# ðŸ§  Prompt Engineering Avanzado

> **Dominando la comunicaciÃ³n con IA.** Ya conoces lo bÃ¡sico. Ahora vamos a tÃ©cnicas avanzadas que usan los profesionales: cuÃ¡ndo usar chain of thought, cÃ³mo estructurar prompts complejos, optimizaciÃ³n de costos y patrones que resuelven problemas de arquitectura.

## ðŸŽ¯ Â¿QuÃ© aprenderÃ¡s aquÃ­?

- âœ… **Chain of Thought:** CuÃ¡ndo y cÃ³mo usar razonamiento estructurado
- âœ… **Role prompting:** Obtener perspectivas expertas especÃ­ficas
- âœ… **OptimizaciÃ³n:** Reducir tokens sin perder calidad
- âœ… **Prompt chaining:** Dividir problemas complejos en pasos
- âœ… **Meta-prompting:** Prompts que mejoran prompts
- âœ… **Casos reales:** Arquitectura, migraciones, code reviews

## ðŸ§© **Chain of Thought: CuÃ¡ndo y cÃ³mo usar**

### **El problema del razonamiento complejo:**

**âŒ Prompt directo (falla con problemas complejos):**
```
"Â¿Por quÃ© mi app Android es lenta?"
â†’ Respuesta genÃ©rica, no aplicable
```

**âœ… Chain of Thought (razonamiento paso a paso):**
```
"Analiza este problema sistemÃ¡ticamente:
1. Primero identifica posibles causas
2. Luego evalÃºa probabilidad de cada una
3. Finalmente propÃ³n diagnÃ³sticos especÃ­ficos"
â†’ AnÃ¡lisis estructurado y actionable
```

### **CuÃ¡ndo usar Chain of Thought:**

**âœ… Ãšsalo para:**
- **Debugging complejo:** MÃºltiples variables interactuando
- **Arquitectura de sistemas:** Decisiones con trade-offs
- **Code reviews:** AnÃ¡lisis multidimensional
- **Migraciones:** MÃºltiples riesgos y consideraciones

**âŒ No lo uses para:**
- **Tareas simples:** "Crea una funciÃ³n que sume dos nÃºmeros"
- **Respuestas rÃ¡pidas:** Cuando necesitas velocidad sobre profundidad
- **LÃ­mite de tokens:** CoT consume mÃ¡s tokens

### **PatrÃ³n de CoT efectivo:**

```
CONTEXTO: [SituaciÃ³n especÃ­fica con detalles]
ANÃLISIS REQUERIDO:
1. [Ãrea especÃ­fica a analizar]
2. [Segunda Ã¡rea]
3. [Tercera Ã¡rea]

Para cada Ã¡rea, proporciona:
- DiagnÃ³stico especÃ­fico
- Evidencia que buscar
- SoluciÃ³n priorizada

INFORMACIÃ“N DISPONIBLE: [Datos concretos]
```

### **CoT con auto-verificaciÃ³n:**

```
PASO 1: DiseÃ±o inicial
[PropÃ³n soluciÃ³n]

PASO 2: ValidaciÃ³n crÃ­tica
Â¿QuÃ© podrÃ­a fallar? Â¿CÃ³mo escala? Â¿QuÃ© falta?

PASO 3: Refinamiento
Ajusta basÃ¡ndote en la validaciÃ³n anterior

PASO 4: ImplementaciÃ³n
Plan concreto y priorizado
```

## ðŸŽ­ **Role Prompting: Perspectivas expertas**

### **Â¿Por quÃ© funciona el role prompting?**

Los LLMs han sido entrenados con contenido de expertos especÃ­ficos. Al adoptar un rol, activan patrones de conocimiento mÃ¡s especÃ­ficos y relevantes.

### **Patrones de roles efectivos:**

**Para anÃ¡lisis tÃ©cnico:**
```
ActÃºa como [SENIOR ROLE] con [X aÃ±os] de experiencia que ha [EXPERIENCIA ESPECÃFICA].

Tu experiencia incluye:
- [SituaciÃ³n relevante 1]
- [SituaciÃ³n relevante 2]
- [Pattern o anti-pattern conocido]

SITUACIÃ“N ACTUAL: [Tu problema]

BasÃ¡ndote en tu experiencia, Â¿quÃ© recomendarÃ­as?
SÃ© especÃ­fico sobre los riesgos que has visto antes.
```

**Para mÃºltiples perspectivas:**
```
Necesito feedback de diferentes roles sobre [DECISIÃ“N]:

PERSPECTIVA 1 - [ROL]: [QuÃ© evaluar]
PERSPECTIVA 2 - [ROL]: [QuÃ© evaluar]
PERSPECTIVA 3 - [ROL]: [QuÃ© evaluar]

Para cada perspectiva:
- Principales concerns
- Deal-breakers si los hay
- RecomendaciÃ³n especÃ­fica
```

### **Roles que funcionan mejor:**

- **"Senior X con Y aÃ±os de experiencia":** MÃ¡s especÃ­fico que "experto"
- **"CTO que ha visto fallar Z":** Experiencia en fracasos es valiosa
- **"Arquitecto que migrÃ³ de A a B":** Experiencia especÃ­fica en transiciones
- **"Developer que mantiene sistema con X usuarios":** Scale-specific knowledge

## ðŸ’° **OptimizaciÃ³n de tokens: Calidad sin costo**

### **El costo oculto de los prompts:**

```
Prompt verboso: 500 tokens Ã— $0.03/1K = $0.015 por request
Prompt optimizado: 150 tokens Ã— $0.03/1K = $0.0045 por request

Con 10K requests/mes: $150 vs $45 = $105 ahorrados/mes
```

### **TÃ©cnicas de compresiÃ³n efectivas:**

**1. Usar abreviaciones estÃ¡ndar:**
```
âŒ "JavaScript application"
âœ… "JS app"

âŒ "database performance optimization"
âœ… "DB perf opt"
```

**2. Estructura concisa:**
```
âŒ "I need you to analyze this code and tell me..."
âœ… "Analyze this code for:"

âŒ "The following information is provided..."
âœ… "CONTEXT:"
```

**3. Bullet points sobre pÃ¡rrafos:**
```
âŒ "The application is experiencing slow response times due to database queries that are not optimized and caching that is not properly implemented."

âœ… "ISSUES:
- Slow DB queries
- Poor caching implementation"
```

### **Mantener calidad en prompts optimizados:**

**Template optimizado que funciona:**
```
TASK: [AcciÃ³n especÃ­fica]
CONTEXT: [MÃ­nimo contexto necesario]
CONSTRAINTS: [Limitaciones importantes]
OUTPUT: [Formato esperado]

[InformaciÃ³n especÃ­fica]
```

## ðŸ”— **Prompt Chaining: Divide y vencerÃ¡s**

### **CuÃ¡ndo usar prompt chaining:**

**âœ… Problemas complejos que requieren:**
- MÃºltiples tipos de anÃ¡lisis
- Decisiones secuenciales
- ValidaciÃ³n entre pasos
- Diferentes tipos de expertise

**âŒ No uses chaining para:**
- Tareas simples que un prompt resuelve
- Cuando necesitas respuesta inmediata
- Procesos que no se benefician de pasos intermedios

### **PatrÃ³n de chaining efectivo:**

```
PASO 1: AnÃ¡lisis â†’ Lista estructurada de findings
PASO 2: SÃ­ntesis â†’ Patrones y relaciones entre findings
PASO 3: SoluciÃ³n â†’ Recomendaciones basadas en sÃ­ntesis
PASO 4: ImplementaciÃ³n â†’ Plan concreto y priorizado
```

### **Ejemplo: Architectural Decision**

**Paso 1 - Requirements Analysis:**
```
Extrae requirements funcionales y no-funcionales de esta descripciÃ³n:
[DescripciÃ³n del proyecto]

OUTPUT: Lista categorizada de requirements
NO propongas soluciones aÃºn.
```

**Paso 2 - Architecture Options:**
```
BasÃ¡ndote en estos requirements: [OUTPUT PASO 1]

PropÃ³n 3 opciones arquitectÃ³nicas diferentes:
- Monolito modular
- Microservicios
- Serverless

Para cada opciÃ³n: pros/cons especÃ­ficos para estos requirements.
```

**Paso 3 - Decision Matrix:**
```
Crea matriz de decisiÃ³n para estas opciones: [OUTPUT PASO 2]

EvalÃºa cada opciÃ³n en:
- Complejidad implementaciÃ³n
- Time to market
- Escalabilidad
- Team expertise required

Recomienda opciÃ³n con justificaciÃ³n.
```

## ðŸ§¬ **Meta-prompting: Prompts que mejoran prompts**

### **Â¿QuÃ© es meta-prompting?**

Usar IA para mejorar tus propios prompts. Es especialmente Ãºtil cuando un prompt no estÃ¡ generando los resultados esperados.

### **PatrÃ³n de debugging de prompts:**

```
Este prompt no genera buenos resultados:

PROMPT PROBLEMÃTICO: "[Tu prompt]"

PROBLEMAS OBSERVADOS:
- [Problema especÃ­fico 1]
- [Problema especÃ­fico 2]

RESULTADOS ESPERADOS:
- [QuÃ© deberÃ­a generar]

REESCRIBE el prompt para:
1. Ser mÃ¡s especÃ­fico
2. Incluir contexto necesario
3. Clarificar el output esperado
```

### **Mejora iterativa:**

```
PROMPT ACTUAL: "[Prompt]"

CRITERIOS DE MEJORA:
1. Â¿Incluye contexto suficiente?
2. Â¿Es especÃ­fico sobre el output?
3. Â¿Considera edge cases?
4. Â¿Es eficiente en tokens?

MEJORA el prompt aplicando estos criterios.
Explica quÃ© cambios hiciste y por quÃ©.
```

## ðŸ¢ **Casos de uso avanzados**

### **1. Code Review SistemÃ¡tico**

```
ActÃºa como senior code reviewer siguiendo estos principios:

1. "Simplicidad sobre cleverness"
2. "Seguridad first, performance second"
3. "Si no se puede testear fÃ¡cilmente, estÃ¡ mal diseÃ±ado"

CÃ“DIGO: [cÃ³digo aquÃ­]

REVISA aplicando cada principio:
- Issues encontrados
- Severity (critical/high/medium/low)
- Refactoring sugerido

Prioriza fixes por severity y impacto.
```

### **2. Migration Planning**

```
ActÃºa como migration specialist con experiencia en [TIPO] migrations.

MIGRACIÃ“N: [TecnologÃ­a A] â†’ [TecnologÃ­a B]

CODEBASE ACTUAL:
- [CaracterÃ­stica 1]
- [CaracterÃ­stica 2]
- [Complejidad especÃ­fica]

MIGRATION STRATEGY:
1. **Risk Assessment**: Â¿QuÃ© puede quebrar?
2. **Phased Approach**: Pasos especÃ­ficos
3. **Rollback Plan**: Si algo falla
4. **Success Metrics**: CÃ³mo medir progreso

CONSTRAINTS:
- Timeline: [X semanas]
- Team size: [X developers]
- Zero downtime requirement
```

### **3. Architecture Decision Records (ADR)**

```
Genera ADR para esta decisiÃ³n arquitectÃ³nica:

CONTEXTO: [SituaciÃ³n que requiere decisiÃ³n]

OPCIONES EVALUADAS:
1. [OpciÃ³n A] - [Pro/con principales]
2. [OpciÃ³n B] - [Pro/con principales]
3. [OpciÃ³n C] - [Pro/con principales]

CRITERIOS DE DECISIÃ“N:
- [Criterio 1]
- [Criterio 2]
- [Criterio 3]

TEAM CONTEXT:
- Experiencia: [nivel]
- Timeline: [restricciÃ³n]
- Constraints: [limitaciones]

FORMATO ADR:
- Status: [proposed/accepted]
- Context: [problema a resolver]
- Decision: [opciÃ³n elegida]
- Consequences: [positivas y negativas]
```

## ðŸ“Š **Midiendo efectividad de prompts**

### **MÃ©tricas para evaluar prompts:**

| **MÃ©trica** | **CÃ³mo medir** | **Target** |
|-------------|----------------|------------|
| **Relevancia** | Â¿Aborda el problema especÃ­fico? | >8/10 |
| **Completitud** | Â¿Cubre todos los requirements? | >90% |
| **Accionabilidad** | Â¿Puedo implementar inmediatamente? | SÃ­/No |
| **PrecisiÃ³n tÃ©cnica** | Â¿El cÃ³digo/soluciÃ³n funciona? | >95% |
| **Eficiencia** | Tokens usados vs valor generado | <200 tokens por insight Ãºtil |

### **A/B testing de prompts:**

```
EXPERIMENTO: Code review prompts

VARIANT A (Control): "Review this code and suggest improvements"

VARIANT B (Structured):
"Review systematically:
1. Correctness
2. Performance
3. Security
4. Maintainability
Prioritize by severity."

MEDIR:
- Tiempo para implementar sugerencias
- NÃºmero de issues reales encontrados
- Calidad de las sugerencias (1-10)
```

## ðŸš€ **Patrones emergentes**

### **Constitutional AI approach:**
```
Sigue estos principios al [TAREA]:

PRINCIPIO 1: [Regla fundamental]
PRINCIPIO 2: [Regla fundamental]
PRINCIPIO 3: [Regla fundamental]

Si hay conflicto entre principios, prioriza en este orden.
Explica trade-offs cuando aplique.
```

### **Debate-style prompting:**
```
Simula debate entre dos expertos sobre [DECISIÃ“N]:

EXPERTO A (Pro-[OPCIÃ“N]): Argumenta ventajas con casos reales
EXPERTO B (Pro-[ALTERNATIVA]): Argumenta contra con experiencias

MODERADOR: Hace preguntas difÃ­ciles a ambos

CONTEXTO: [Tu situaciÃ³n especÃ­fica]
```

## ðŸ’¡ **Best practices consolidadas**

### **Para prompts de producciÃ³n:**

1. **SÃ© especÃ­fico sobre el contexto:** "App React con 50K usuarios" vs "app web"
2. **Define output format:** JSON, bullet points, cÃ³digo con tests
3. **Incluye constrainsts:** Timeline, team size, tech stack
4. **Usa ejemplos cuando sea complejo:** Few-shot para patrones especÃ­ficos
5. **AÃ±ade validaciÃ³n:** "Â¿Falta algo en esta soluciÃ³n?"

### **Para optimizaciÃ³n de costos:**

1. **Estructura jerÃ¡rquica:** Contexto â†’ Task â†’ Constraints â†’ Output
2. **Abreviaciones estÃ¡ndar:** JS, DB, API, perf, opt
3. **Bullet points:** MÃ¡s densos que pÃ¡rrafos
4. **Reusar prompts:** Templates para casos similares

### **Para casos complejos:**

1. **Chain cuando hay mÃºltiples tipos de anÃ¡lisis**
2. **Role prompting para expertise especÃ­fica**
3. **Meta-prompting cuando los resultados no son buenos**
4. **A/B testing para optimizar prompts crÃ­ticos**

---

## ðŸš€ **Â¿QuÃ© sigue?**

Dominas tÃ©cnicas avanzadas de prompt engineering. Ahora vamos a ver cÃ³mo desarrollar aplicaciones completas con LLMs:

**âž¡ï¸ [Siguiente: Desarrollo con LLMs](./desarrollo-llms.md)**

---

## ðŸ’¡ **Key Takeaways**

- **Chain of Thought:** Para problemas complejos, no para tareas simples
- **Role prompting:** Activa conocimiento especÃ­fico en LLMs
- **OptimizaciÃ³n:** 70% reducciÃ³n de tokens sin perder calidad
- **Chaining:** Divide problemas complejos en pasos manejables
- **Meta-prompting:** Usa IA para mejorar tus propios prompts

*El prompt engineering avanzado es la diferencia entre respuestas genÃ©ricas y soluciones profesionales. Estas tÃ©cnicas te permiten obtener valor real de IA en problemas complejos de arquitectura y desarrollo.*